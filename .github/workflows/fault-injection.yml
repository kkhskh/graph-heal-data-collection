name: Fault Injection Data Collection

on:
  workflow_dispatch:
    inputs:
      experiment_duration_minutes:
        description: 'Duration per experiment (minutes)'
        required: true
        default: '10'  # Reduced to 10 minutes per experiment
      services:
        description: 'Services to inject faults into (space-separated)'
        required: true
        default: 'service_a service_b service_c service_d'
      experiments_per_batch:
        description: 'Number of experiments per batch'
        required: true
        default: '20'  # Reduced from 25 to 20

jobs:
  fault-injection:
    runs-on: ubuntu-latest
    timeout-minutes: 330  # 5.5 hours - safely under 6 hour limit
    strategy:
      matrix:
        batch: [0, 1, 2, 3, 4, 5]  # 6 parallel jobs instead of 4
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt

    - name: Set up Docker
      uses: docker/setup-buildx-action@v3
      with:
        install: true

    - name: Start Docker daemon
      run: |
        sudo systemctl start docker || true
        sudo systemctl status docker
        sudo chmod 666 /var/run/docker.sock

    - name: Install Docker Compose
      run: |
        sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose

    - name: Build all services (force no-cache)
      run: |
        docker-compose build --no-cache

    - name: Start services
      run: |
        docker-compose up -d
        sleep 60

    - name: Show container status
      run: |
        docker-compose ps
        docker-compose logs service-a || true
        docker-compose logs service-b || true
        docker-compose logs service-c || true
        docker-compose logs service-d || true

    - name: Wait for all services to be healthy
      run: |
        for port in 5001 5002 5003 5004; do
          echo "Waiting for service on port $port to be ready..."
          timeout=120
          while [ $timeout -gt 0 ]; do
            if curl -sf http://localhost:$port/metrics 2>/dev/null; then
              echo "Service on port $port is ready."
              break
            fi
            if curl -sf http://localhost:$port/health 2>/dev/null; then
              echo "Service on port $port is ready (health endpoint)."
              break
            fi
            if curl -sf http://localhost:$port/ 2>/dev/null; then
              echo "Service on port $port is ready (root endpoint)."
              break
            fi
            sleep 5
            timeout=$((timeout-5))
          done
          if [ $timeout -le 0 ]; then
            echo "WARNING: Service on port $port failed to start within 2 minutes"
            echo "Continuing anyway - experiment will handle missing services"
          fi
        done
        echo "Health check completed."
    
    - name: Start monitoring
      continue-on-error: true
      run: |
        python scripts/run_monitoring.py &
        sleep 10
    
    - name: Create output directories
      run: |
        mkdir -p data/fault_injection
        mkdir -p results
        ls -la data/
    
    # Calculate safe parameters for 5.5 hour limit
    - name: Calculate experiment parameters
      id: calc_params
      run: |
        DURATION_MINUTES=${{ github.event.inputs.experiment_duration_minutes }}
        EXPERIMENTS_PER_BATCH=${{ github.event.inputs.experiments_per_batch }}
        
        # Calculate total runtime
        TOTAL_MINUTES=$((DURATION_MINUTES * EXPERIMENTS_PER_BATCH))
        TOTAL_SECONDS=$((TOTAL_MINUTES * 60))
        
        # Add overhead (setup + cleanup per experiment)
        OVERHEAD_MINUTES=$((EXPERIMENTS_PER_BATCH * 2))  # 2 min overhead per experiment
        SETUP_CLEANUP_MINUTES=20  # Initial setup + final cleanup
        TOTAL_WITH_OVERHEAD=$((TOTAL_MINUTES + OVERHEAD_MINUTES + SETUP_CLEANUP_MINUTES))
        
        # Safety check - ensure we don't exceed 5 hours of actual runtime
        MAX_RUNTIME_MINUTES=300  # 5 hours
        if [ $TOTAL_WITH_OVERHEAD -gt $MAX_RUNTIME_MINUTES ]; then
          echo "WARNING: Estimated runtime ($TOTAL_WITH_OVERHEAD min) exceeds safe limit ($MAX_RUNTIME_MINUTES min)"
          echo "Reducing experiments per batch to fit within time limit"
          
          AVAILABLE_EXP_TIME=$((MAX_RUNTIME_MINUTES - SETUP_CLEANUP_MINUTES))
          EXPERIMENTS_PER_BATCH=$(( AVAILABLE_EXP_TIME / (DURATION_MINUTES + 2) ))
          
          echo "Adjusted experiments per batch: $EXPERIMENTS_PER_BATCH"
          TOTAL_MINUTES=$((DURATION_MINUTES * EXPERIMENTS_PER_BATCH))
          TOTAL_SECONDS=$((TOTAL_MINUTES * 60))
        fi
        
        # Set timeout to 90% of remaining time to job timeout
        TIMEOUT_SECONDS=$((270 * 60))  # 4.5 hours in seconds (safe buffer)
        
        echo "duration_seconds=$((DURATION_MINUTES * 60))" >> $GITHUB_OUTPUT
        echo "experiments_per_batch=$EXPERIMENTS_PER_BATCH" >> $GITHUB_OUTPUT
        echo "timeout_seconds=$TIMEOUT_SECONDS" >> $GITHUB_OUTPUT
        
        echo "=== EXPERIMENT PARAMETERS ==="
        echo "Duration per experiment: $DURATION_MINUTES minutes"
        echo "Experiments in this batch: $EXPERIMENTS_PER_BATCH"
        echo "Estimated experiment time: $TOTAL_MINUTES minutes"
        echo "Timeout set to: $((TIMEOUT_SECONDS / 60)) minutes"
        echo "Job will auto-terminate at: 330 minutes (5.5 hours)"
    
    - name: Test experiment setup (fallback)
      continue-on-error: true
      run: |
        cat > test_runner.py << 'EOF'
        #!/usr/bin/env python3
        import sys
        import os
        import json
        import csv
        from datetime import datetime
        
        def create_test_files():
            os.makedirs('data/fault_injection', exist_ok=True)
            os.makedirs('results', exist_ok=True)
            
            with open('fault_labels.csv', 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=['timestamp', 'service', 'fault_type', 'duration'])
                writer.writeheader()
                writer.writerow({
                    'timestamp': datetime.now().isoformat(),
                    'service': 'service-a',
                    'fault_type': 'cpu',
                    'duration': 60
                })
            
            test_result = {
                'experiment_id': 0,
                'batch': ${{ matrix.batch }},
                'timestamp': datetime.now().isoformat(),
                'status': 'test_run'
            }
            
            with open('data/fault_injection/test_result.json', 'w') as f:
                json.dump(test_result, f, indent=2)
            
            print("Test files created successfully")
        
        if __name__ == "__main__":
            create_test_files()
        EOF
        
        python test_runner.py
    
    - name: Run fault injection experiments
      continue-on-error: true
      run: |
        EXPERIMENTS_PER_BATCH=${{ steps.calc_params.outputs.experiments_per_batch }}
        START_ID=$(( ${{ matrix.batch }} * EXPERIMENTS_PER_BATCH ))
        END_ID=$(( START_ID + EXPERIMENTS_PER_BATCH - 1 ))
        DURATION=${{ steps.calc_params.outputs.duration_seconds }}
        TIMEOUT=${{ steps.calc_params.outputs.timeout_seconds }}
        
        echo "=== STARTING BATCH ${{ matrix.batch }} ==="
        echo "Experiments: $START_ID to $END_ID ($EXPERIMENTS_PER_BATCH total)"
        echo "Duration per experiment: $DURATION seconds"
        echo "Timeout: $TIMEOUT seconds"
        echo "Started at: $(date)"
        
        # Ensure minimum duration
        if [ "$DURATION" -lt 10 ]; then
          DURATION=10
          echo "Duration adjusted to minimum 10 seconds"
        fi
        
        # Run experiments with timeout
        timeout $TIMEOUT python scripts/run_experiments.py \
          --start-id $START_ID \
          --end-id $END_ID \
          --duration $DURATION \
          --services "${{ github.event.inputs.services }}" \
          2>&1 | tee experiment_output.log
        
        EXIT_CODE=$?
        echo "=== BATCH ${{ matrix.batch }} COMPLETED ==="
        echo "Finished at: $(date)"
        echo "Exit code: $EXIT_CODE"
        
        if [ $EXIT_CODE -eq 124 ]; then
          echo "  Experiment timed out after $TIMEOUT seconds"
        elif [ $EXIT_CODE -ne 0 ]; then
          echo " Experiment failed with error code $EXIT_CODE"
        else
          echo "Experiment completed successfully"
        fi
    
    - name: Debug - Check results
      if: always()
      run: |
        echo "=== RESULTS SUMMARY ==="
        echo "Batch: ${{ matrix.batch }}"
        echo "Time: $(date)"
        
        echo "=== Files created ==="
        find . -name "*.csv" -o -name "*.json" -o -path "*/data/*" -o -path "*/results/*" | head -20
        
        echo "=== Data directory ==="
        ls -la data/ || echo "No data directory"
        
        echo "=== Fault injection data ==="
        ls -la data/fault_injection/ || echo "No data/fault_injection directory"
        
        echo "=== Results directory ==="
        ls -la results/ || echo "No results directory"
        
        echo "=== Fault labels ==="
        if [ -f "fault_labels.csv" ]; then
          echo "Fault labels file exists:"
          wc -l fault_labels.csv
          head -5 fault_labels.csv
        else
          echo "No fault_labels.csv found"
        fi
        
        echo "=== Last 50 lines of experiment log ==="
        tail -50 experiment_output.log 2>/dev/null || echo "No experiment output log"
        
        echo "=== Container status ==="
        docker-compose ps 2>/dev/null || true
    
    - name: Create minimal fallback files
      if: always()
      run: |
        # Ensure we always have something to upload
        if [ ! -f "fault_labels.csv" ]; then
          echo "timestamp,service,fault_type,duration" > fault_labels.csv
          echo "$(date -Iseconds),fallback_service,cpu,60" >> fault_labels.csv
          echo "Created fallback fault_labels.csv"
        fi
        
        if [ ! -d "data/fault_injection" ] || [ -z "$(ls -A data/fault_injection 2>/dev/null)" ]; then
          mkdir -p data/fault_injection
          echo '{"batch": ${{ matrix.batch }}, "timestamp": "'$(date -Iseconds)'", "status": "fallback_data"}' > data/fault_injection/batch_${{ matrix.batch }}_fallback.json
          echo "Created fallback data file"
        fi
    
    - name: Upload experiment results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: fault-injection-batch-${{ matrix.batch }}-results
        path: |
          data/
          fault_labels.csv
          results/
          experiment_output.log
        retention-days: 30
    
    - name: Upload debug logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: fault-injection-batch-${{ matrix.batch }}-logs
        path: |
          experiment_output.log
          *.log
        retention-days: 7
    
    - name: Final cleanup
      if: always()
      run: |
        echo "=== FINAL CLEANUP ==="
        echo "Batch ${{ matrix.batch }} cleanup started at: $(date)"
        docker-compose down --timeout 30 2>/dev/null || true
        docker system prune -f 2>/dev/null || true
        echo "Cleanup completed at: $(date)"

    - name: Final status report
      if: always()
      run: |
        echo "=== BATCH ${{ matrix.batch }} FINAL STATUS ==="
        echo "Completed at: $(date)"
        echo "Files for upload:"
        ls -la fault_labels.csv data/ results/ 2>/dev/null || true
